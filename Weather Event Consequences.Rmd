---
title: "Weather Event Consequences"
author: "GP"
date: "9/26/2020"
output: 
  html_document: 
    fig_width: 10
    keep_md: yes
---
*NOTE:  rmarkdown::render('PA1_template.Rmd', clean = FALSE)* to knit

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# SYNOPSIS
This analysis summarizes storms and severe weather events that have impacted human health or caused great economic impact. The data set was derived from the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database and covers records from the year 1950 to November 2011. The goal of the analysis was to find which types of events are most harmful to population health and which have the greatest economic consequences.

The analysis indicates that the most harmful weather events to humans, in terms of fatalities and injuries, are ....% fr total?

The analysis also indicates that the weather events that cause the greatest economic damage are...

# DATA PROCESSING
A little research found that information about the about the original variables can be found here: 
[https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Export-Format.pdf]
The data we are given for this analysis is a subset, with renamed and possibly compromised formatting. That being said, sometimes data is messy, so here is how this particular dataset is processed to answer the questions. Disclaimer: no public government or municipality should rely on this report.

The analysis was conducted using the following computer and software:
``` {r environ }
print(Sys.info()[c('sysname','machine','release')])
print(R.Version()['version.string'])
```

### Import raw data and extract. Install needed libraries
Importing and extracting the large data set uses significant time.This only needs to be done once however, and further analyses will run faster with the data extracted.

```{r setup ,cache = TRUE}
library(cowplot)
library(dplyr)
library(tidyr)
library(ggplot2)
library(R.utils)
library(lubridate)
library(lattice)
```

```{r import, cache = TRUE}
t1 <- Sys.time()
bunzip2("repdata_data_StormData.csv.bz2","StormData.csv", remove = FALSE, skip = TRUE)
t2 <- Sys.time()
print(t2-t1)  #Time difference of 19.25788 secs on my machine

#Load raw data into R
t3 <- Sys.time()
StormData <- read.csv("StormData.csv",sep = ",")
t4 <- Sys.time()
print(t4-t3)   #Time difference of 24.37243 secs on my machine
```

The raw data, a dataframe called StormData, is now in R. The data looks like:
```{r StormData}
print(str(StormData, give.length = TRUE))
# Missing data often shown as "" rather than NAs. 
# There are 985 unique events listed, but the documentation lists 48 Storm Events
# print(unique(StormData$EVTYPE))  # returns list of 985 events (too big to show here)
```
The "" is replaced with NA, and the date format is cast into a useful format. New dataframe is 'sd1'. Now the analysis can begin.
```{r newRaw, cache= TRUE}
sd1 <-na_if(StormData[,],"")   #this is slow.
sd1$BGN_DATE <- date(mdy_hms(sd1$BGN_DATE))
```

## Across the United States, which types of events (EVTYPE variable) are most harmful with respect to population health?
Events (EVTYPE variable) that cause deaths or injuries are harmful. The analysis finds the single worst event in terms of injuries and in terms of death. Then the analysis will group similar EVTYPE names, for example 'TORNADO' and 'FUNNEL' and find the total injuries and deaths across all the years. The results will then be summarized.

### Scatter plot of the raw data INJURIES, FATALITIES versus EVTYPE
The initial look at the data using a scatter plot indicated clusters and peaks that have high harm. The problem is that many event types have similar, ambiguous, or poorly worded values (such as '?', or 'none', or 'torndao', etc.), which results in the 985 unique event types when there really should be only 48 according to the documentation. These problems will be addressed next. The initial plot and the determination of the maximum values is programmed with this code: 

```{r rawScatterAndPeaks, cache=TRUE, fig.width = 9, fig.height = 3, fig.cap= "Raw Storm Data Scatter Plot}
#FATALITIES AND INJURIES plotted Together
p3 <-ggplot(data =sd1,
            aes(EVTYPE))+
  ylab("Fatalities and Injuries")+
  xlab("985 event types") +
  geom_point(aes(y = INJURIES, colour = 'Injuries'))+
  geom_point(aes(y = FATALITIES, colour = 'Fatalities'))+
  theme(axis.text.x = element_blank())+
  labs(title = "Raw data scatter plot")
print(p3)

#Find max of single events:
maxInjIndex  <- which.max(sd1$INJURIES)
maxInj <- sd1$INJURIES[maxInjIndex]
eventMaxInj <- sd1$EVTYPE[maxInjIndex]   # "Tornado
dateMaxInj <- mdy_hms(StormData$BGN_DATE)[maxInjIndex]  #1979-04-10
remarksMaxInj <- StormData$REMARKS[maxInjIndex]

maxFatIndex  <- which.max(sd1$FATALITIES)
maxFat <- sd1$FATALITIES[maxFatIndex]
eventMaxFat <- sd1$EVTYPE[maxFatIndex]   # "Heat
dateMaxFat <- mdy_hms(StormData$BGN_DATE)[maxFatIndex]  #1995-07-12
remarksMaxFat <- StormData$REMARKS[maxFatIndex]
```
The single highest day of injury was from a `r eventMaxInj` which occurred on `r dateMaxInj` and caused `r maxInj` injuries. 

The single highest day of fatalities was from a `r eventMaxFat` which occurred on `r dateMaxFat` and caused `r maxFat` injuries. 

A synopsis of the extreme fatality event can be found in the REMARKS variable. A clip is shown below. The fatality event stands out, as it does not correspond to a cluster of fatality events on the raw data scatter plot; so perhaps another event type causes more fatalities overall. However, max injuries from tornadoes does correspond to many such tornado events. Further investigation is warranted. Note: no remarks were submitted for the Injury event.

```{r remarksFat}
print(substr(remarksMaxFat,1,542))
```

```{r remarksInj}
print(substr(remarksMaxInj,1,542))
```
### Further analysis, consolidating events

Quantify by summing top 1000 events with the most injuries or fatalities. This determines the event types with overall worst injury and fatality record. The steps are to get the top 1000, then look at the EVTYPEs, then consolidate similar names. This was an iterative process initially. The final step will be to apply the consolidation to the original data (to reduce the 985 EVTYPES), and confirm that the peaks in the original data are the same, and that no significant other peaks have appeared.

Fortunately, the top 1000 did not include some of the outliers, i.e. events that occurred relatively few times, did not have high injuries and fatalities, and had poor naming conventions. These events get lumped together. Some of these negligible events can be grouped with the high impact events when the REMARKS variable is read, if desired, but are not likely to change the overall outcome. 

```{r consolidateInjAndFat, cache = TRUE}
sd2 <- sd1 %>% select(c(FATALITIES,INJURIES,EVTYPE,REFNUM,BGN_DATE))
#Look at top 1000 injury and fatality count events
#Create subset of top 1000
injOrderInd <-order(sd2$INJURIES,decreasing = TRUE)  # gets index of max inj and sorts
injOrderFat <-order(sd2$FATALITIES,decreasing = TRUE)# gets index of max Fat and sorts

top1000Injdf <- sd2[injOrderInd[1:1000],]
top1000Fatdf <- sd2[injOrderFat[1:1000],]

injUniq <- unique(top1000Injdf$EVTYPE) #45 evtypes returned
fatUniq <- unique(top1000Fatdf$EVTYPE) #71

# Want the event types to be grouped 
top1000Injdf$EVTYPE[grep("TORNA|SPOUT",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Tornado"
top1000Injdf$EVTYPE[grep("HEAT",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Heat"
top1000Injdf$EVTYPE[grep("WINTER|BLIZZARD|SNOW",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "snow"
top1000Injdf$EVTYPE[grep("ICE|MIX|GLAZE",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Ice"
top1000Injdf$EVTYPE[grep("THUNDER|TSTM|LIGHTN",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Tstorm"
top1000Injdf$EVTYPE[grep("HURRIC|TROPICAL",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Hurricane "
top1000Injdf$EVTYPE[grep("FLOOD",top1000Injdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Flood "
#22 categories now

top1000Fatdf$EVTYPE[grep("TORNA|SPOUT",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Tornado"
top1000Fatdf$EVTYPE[grep("HEAT",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Heat"
top1000Fatdf$EVTYPE[grep("WINTER|BLIZZARD|SNOW",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "snow"
top1000Fatdf$EVTYPE[grep("ICE|MIX|GLAZE",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Ice"
top1000Fatdf$EVTYPE[grep("THUNDER|TSTM|LIGHTN",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Tstorm"
top1000Fatdf$EVTYPE[grep("HURRIC|TROPICAL",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Hurricane "
top1000Fatdf$EVTYPE[grep("FLOOD",top1000Fatdf$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Flood "
# 42 categories now
```
At this point a few plots will show that this reduced data set will make a scatter plot similar to the original, but with less points, indicating a reasonable grouping of events. (not shown). Next, find the sum of injuries and fatalities as a function of the events in the reduced data set. Recall we are neglecting outliers.

```{r InjFatSums, cache = TRUE}
InjSums <-top1000Injdf %>% group_by(EVTYPE) %>%
  summarise(totInjuries = sum(INJURIES)) %>% arrange(desc(totInjuries),by_group = TRUE)
print(InjSums[1:10,])   #Tornado, Heat, Flood, snow...

FatSums <-top1000Fatdf %>% group_by(EVTYPE) %>%
  summarise(totFatalities = sum(FATALITIES)) %>% arrange(desc(totFatalities),by_group = TRUE)
print(FatSums[1:10,])

#For both injuries and fatalities, order is : Tornado, Heat, Flood
```

Now apply a similar filter to the original data set and confirm groupings are the same to validate the sums obtained above are indeed indicative of events that cause the most harm and injuries. Some additional terms for the grep function were added to help reduce outliers. Illustrate with a plot.

Create new plot that will be combined with the first plot to validate event consolidation.Note that the new plot has a horizontal scale slightly stretched (less categories), but peak matching can still be observed.

```{r consolidatedInjFatPlot, cache = TRUE, fig.width = 9, fig.height = 7, fig.cap = "Comparison of raw data scatter plot with consolidated events scatter plot}

sd3 <- sd1
#These matching criteria were iteratively determined
sd3$EVTYPE[grep("TORN|SPOUT|WHIRL|GUSTNA|FUNNE|ROTAT",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Tornado"
sd3$EVTYPE[grep("HAIL",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Hail"
sd3$EVTYPE[grep("HEAT|HOT|WARM|HIGH TEMP",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Heat"
sd3$EVTYPE[grep("WINT|BLIZZARD|SNOW|COLD|SLEET|FREEZ",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "snow"
sd3$EVTYPE[grep("ICE|MIX|GLAZE|ICY",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Ice"
sd3$EVTYPE[grep("THUNDER|TSTM|LIG|BURST|TURBU",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Tstorm"
sd3$EVTYPE[grep("HURRIC|TROPICAL|TYPHO",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Hurricane "
sd3$EVTYPE[grep("FLOOD|FLD|DAM BR",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Flood "
sd3$EVTYPE[grep("SUMMARY|OTHER|[:?:]|NONE",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "tbd"
sd3$EVTYPE[grep("FIRE|SMOKE",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Fire"
sd3$EVTYPE[grep("MUD|LANDS|ROCK",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Mud"
sd3$EVTYPE[grep("VOLCAN|VOG",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Volcanic"
sd3$EVTYPE[grep("GLAZE|BLACK ICE",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Black_Ice"
sd3$EVTYPE[grep("DROUGHT|DRY|DRIE",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Drought"
sd3$EVTYPE[grep("WIND|WND",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Winds"  #includes some TSTM
sd3$EVTYPE[grep("FROST|COOL",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Cool"  #includes frost
sd3$EVTYPE[grep("SURF|SEA|TIDE|CURRENT|MARINE|TSUN|BEACH|WAVE|SWELL|SURGE|COASTAL",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Marine"
sd3$EVTYPE[grep("RAIN|WET|PRECIP|SHOWER",sd3$EVTYPE,ignore.case = TRUE,fixed = FALSE)] <- "Rain"

#add consolidated events to sd1 for nice facet or dual plot
sd4 <-data.frame(cbind(FATALITIES=sd1$FATALITIES,
            INJURIES= sd1$INJURIES,
            EVTYPE=sd1$EVTYPE,EVTYPEsub = sd3$EVTYPE))

#print(unique(sd4$EVTYPEsub))  #66 event categories

#Try to get all the pre and post data reduction together
#Note p5 will be shown in the 'before and after' plot of p35.
p5 <-ggplot(data =sd4,
            aes(EVTYPEsub,INJURIES))+
  ylab("Fatalities and Injuries")+
  xlab("66 event catagories") +
  geom_point(aes(y = as.numeric(INJURIES), colour = 'Injuries'))+
  geom_point(aes(y = as.numeric(FATALITIES), colour = 'Fatalities'))+
  theme(axis.text.x = element_text(angle = 90))+
  labs(title = "Weather events consolidated")


p35 <-cowplot::plot_grid(p3,p5,nrow = 2, ncol = 1)
print(p35) 

```

## Across the United States, which types of events have the greatest economic consequences?

# Results

The analysis began with the raw data, then with a subset of data consisting of the most injurious or fatal events, to extract the overall events most harmful to population health. The analysis subsequently verified consolidating the untidy list of event types was a valid method of data consolidation. The table below shows that tornados are the extreme weather event that caused both the most injuries and the most fatalities between 1950 and November 2011. This is followed by heat related events.
